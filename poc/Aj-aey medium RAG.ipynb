{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is for blind implement RAG concept on medium blog by AJ Aey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.11.16-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.4.0,>=0.3.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-cli<0.4.0,>=0.3.1 (from llama-index)\n",
      "  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.16 (from llama-index)\n",
      "  Downloading llama_index_core-0.11.16-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.4 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.3.0,>=0.2.10 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.2.11-py3-none-any.whl.metadata (649 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.2.2-py3-none-any.whl.metadata (678 bytes)\n",
      "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
      "  Downloading openai-1.51.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (6.0.1)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.35-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (3.10.5)\n",
      "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (1.26.4)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.0 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading tiktoken-0.8.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.16->llama-index) (4.11.0)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.2-py3-none-any.whl.metadata (763 bytes)\n",
      "Requirement already satisfied: pandas in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.2.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.3.0->llama-index)\n",
      "  Downloading llama_parse-0.5.7-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting click (from nltk>3.8.1->llama-index)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.11.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.5)\n",
      "Requirement already satisfied: anyio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (4.2.0)\n",
      "Requirement already satisfied: certifi in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.0.2)\n",
      "Requirement already satisfied: idna in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (3.7)\n",
      "Requirement already satisfied: sniffio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.16->llama-index) (0.14.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index)\n",
      "  Downloading jiter-0.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading pydantic_core-2.23.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.16->llama-index) (2.2.3)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.16->llama-index)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2023.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.16->llama-index) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\n",
      "Downloading llama_index-0.11.16-py3-none-any.whl (6.8 kB)\n",
      "Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.11.16-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl (10 kB)\n",
      "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.2.11-py3-none-any.whl (12 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.2.2-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading llama_cloud-0.1.2-py3-none-any.whl (173 kB)\n",
      "Downloading llama_parse-0.5.7-py3-none-any.whl (10 kB)\n",
      "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.51.0-py3-none-any.whl (383 kB)\n",
      "Downloading pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp312-cp312-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.8.0-cp312-cp312-macosx_11_0_arm64.whl (982 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m982.6/982.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-macosx_11_0_universal2.whl (274 kB)\n",
      "Downloading jiter-0.5.0-cp312-cp312-macosx_11_0_arm64.whl (296 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: striprtf, dirtyjson, wrapt, tenacity, SQLAlchemy, pypdf, pydantic-core, pillow, networkx, mypy-extensions, marshmallow, joblib, jiter, greenlet, distro, click, annotated-types, typing-inspect, tiktoken, pydantic, nltk, deprecated, openai, llama-cloud, dataclasses-json, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed SQLAlchemy-2.0.35 annotated-types-0.7.0 click-8.1.7 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 greenlet-3.1.1 jiter-0.5.0 joblib-1.4.2 llama-cloud-0.1.2 llama-index-0.11.16 llama-index-agent-openai-0.3.4 llama-index-cli-0.3.1 llama-index-core-0.11.16 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.4.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.11 llama-index-multi-modal-llms-openai-0.2.2 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.7 marshmallow-3.22.0 mypy-extensions-1.0.0 networkx-3.3 nltk-3.9.1 openai-1.51.0 pillow-10.4.0 pydantic-2.9.2 pydantic-core-2.23.4 pypdf-4.3.1 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.8.0 typing-inspect-0.9.0 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-readers-elasticsearch\n",
      "  Downloading llama_index_readers_elasticsearch-0.2.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-readers-elasticsearch) (0.11.16)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.11.0)\n",
      "Requirement already satisfied: click in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (3.22.0)\n",
      "Requirement already satisfied: anyio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-readers-elasticsearch) (24.1)\n",
      "Downloading llama_index_readers_elasticsearch-0.2.1-py3-none-any.whl (3.3 kB)\n",
      "Installing collected packages: llama-index-readers-elasticsearch\n",
      "Successfully installed llama-index-readers-elasticsearch-0.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-readers-elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-opensearch\n",
      "  Downloading llama_index_vector_stores_opensearch-0.3.0-py3-none-any.whl.metadata (728 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-vector-stores-opensearch) (0.11.16)\n",
      "Collecting opensearch-py<3.0.0,>=2.4.2 (from opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch)\n",
      "  Downloading opensearch_py-2.7.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from opensearch-py<3.0.0,>=2.4.2->opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi>=2024.07.04 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from opensearch-py<3.0.0,>=2.4.2->opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch) (2024.8.30)\n",
      "Collecting Events (from opensearch-py<3.0.0,>=2.4.2->opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch)\n",
      "  Downloading Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: urllib3!=2.2.0,!=2.2.1,<3,>=1.26.19 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from opensearch-py<3.0.0,>=2.4.2->opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch) (2.2.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.11.0)\n",
      "Requirement already satisfied: click in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (3.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (3.22.0)\n",
      "Requirement already satisfied: anyio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from python-dateutil->opensearch-py<3.0.0,>=2.4.2->opensearch-py[async]<3.0.0,>=2.4.2->llama-index-vector-stores-opensearch) (1.16.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-vector-stores-opensearch) (24.1)\n",
      "Downloading llama_index_vector_stores_opensearch-0.3.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading opensearch_py-2.7.1-py3-none-any.whl (325 kB)\n",
      "Downloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
      "Installing collected packages: Events, opensearch-py, llama-index-vector-stores-opensearch\n",
      "Successfully installed Events-0.5 llama-index-vector-stores-opensearch-0.3.0 opensearch-py-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-vector-stores-opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-ollama\n",
      "  Downloading llama_index_embeddings_ollama-0.3.1-py3-none-any.whl.metadata (693 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-embeddings-ollama) (0.11.16)\n",
      "Collecting ollama<0.4.0,>=0.3.1 (from llama-index-embeddings-ollama)\n",
      "  Downloading ollama-0.3.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (4.11.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.11.0)\n",
      "Requirement already satisfied: anyio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.14.0)\n",
      "Requirement already satisfied: click in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.22.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (24.1)\n",
      "Downloading llama_index_embeddings_ollama-0.3.1-py3-none-any.whl (2.6 kB)\n",
      "Downloading ollama-0.3.3-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: ollama, llama-index-embeddings-ollama\n",
      "Successfully installed llama-index-embeddings-ollama-0.3.1 ollama-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-embeddings-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest-asyncio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl.metadata (718 bytes)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.24.6)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-embeddings-huggingface) (0.11.16)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: filelock in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.11.0)\n",
      "Requirement already satisfied: aiohttp in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.10.5)\n",
      "Collecting minijinja>=1.0 (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface)\n",
      "  Downloading minijinja-2.2.0-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.0.35)\n",
      "Requirement already satisfied: dataclasses-json in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.8.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.44.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading torch-2.4.1-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.11.0)\n",
      "Requirement already satisfied: click in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.1.1)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: jinja2 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (75.1.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.4.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (3.22.0)\n",
      "Requirement already satisfied: anyio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.1.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.3.1-py3-none-any.whl (8.6 kB)\n",
      "Downloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
      "Downloading minijinja-2.2.0-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.4.1-cp312-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, threadpoolctl, sympy, scipy, minijinja, torch, scikit-learn, sentence-transformers, llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.3.1 minijinja-2.2.0 mpmath-1.3.0 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.1.1 sympy-1.13.3 threadpoolctl-3.5.0 torch-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now preparation section has completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/SS2305_1MH01/anaconda-env/kdai-llm-final/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.vector_stores.opensearch import OpensearchVectorStore, OpensearchVectorClient\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import torch\n",
    "import nest_asyncio\n",
    "from os import getenv\n",
    "\n",
    "# Apply nest_asyncio to avoid runtime errors in Jupyter notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Check if CUDA is available for GPU acceleration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now setup hybrid search pipeline on opensearch.\n",
    "to run this code, ensure opensearch container is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true}"
     ]
    }
   ],
   "source": [
    "! curl -XPUT \"http://localhost:9200/_search/pipeline/hybrid-search-pipeline\" -H 'Content-Type: application/json' -d' \\\n",
    "{ \\\n",
    "  \"description\": \"Pipeline for hybrid search\", \\\n",
    "  \"phase_results_processors\": [ \\\n",
    "    { \\\n",
    "      \"normalization-processor\": { \\\n",
    "        \"normalization\": { \\\n",
    "          \"technique\": \"min_max\" \\\n",
    "        }, \\\n",
    "        \"combination\": { \\\n",
    "          \"technique\": \"harmonic_mean\", \\\n",
    "          \"parameters\": { \\\n",
    "            \"weights\": [ \\\n",
    "              0.3, \\\n",
    "              0.7 \\\n",
    "            ] \\\n",
    "          } \\\n",
    "        } \\\n",
    "      } \\\n",
    "    } \\\n",
    "  ] \\\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load and process PDF documents\n",
    "In this step, we’ll load PDF documents and convert them into a format suitable for further processing, using Llama Index to help manage the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Load PDF documents:\n",
    "Explanation: We use SimpleDirectoryReader to load PDF files from a specified directory. This function is part of Llama Index and is designed to handle various document formats, including PDFs. It automatically extracts text content from the PDFs, making it easier to process the information in subsequent steps.\n",
    "\n",
    "PDF file containing the article 291 judgement will be placed in this folder.\n",
    "it will not be part of opensearch container. it will also not sync to github.\n",
    "this data source will be compressed and backup on onedrive instead of github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the folder on the external disk\n",
    "external_disk_path = \"/Volumes/SS2305_1MH01/data-src/kdai-llm-final-20241007/pdf_corpus\"  # macOS/Linux\n",
    "# external_disk_path = \"D:/pdf_corpus\"  # Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "#reader = SimpleDirectoryReader(input_dir=\"pdf_corpus\",recursive=True)\n",
    "reader = SimpleDirectoryReader(input_dir=external_disk_path,recursive=True)\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Split documents into chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|██████████| 88/88 [00:00<00:00, 310.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "splitter = TokenTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=128,\n",
    "    separator=\" \",\n",
    ")\n",
    "token_nodes = splitter.get_nodes_from_documents(\n",
    "    documents, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generate embeddings using the BAAI/bge-m3 model\n",
    "In this step, we’ll use the BAAI/bge-m3 model to generate embeddings for our text chunks. These embeddings are crucial for semantic search and understanding the content of our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "embedding_model_name = 'BAAI/bge-m3'\n",
    "embedding_model = HuggingFaceEmbedding(model_name=embedding_model_name,max_length=512, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding dimension of example text ===> 1024\n"
     ]
    }
   ],
   "source": [
    "embeddings = embedding_model.get_text_embedding(\"box\")\n",
    "dim = len(embeddings)\n",
    "print(\"embedding dimension of example text ===>\",dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Setup and Initialize OpenSearch Vector Client\n",
    "In this step, we’ll set up and initialize the OpenSearch Vector Client, preparing our system to use OpenSearch as a vector database for efficient similarity searches in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1 Set up OpenSearch connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "from llama_index.vector_stores.opensearch import (\n",
    "    OpensearchVectorStore,\n",
    "    OpensearchVectorClient,\n",
    ")\n",
    "\n",
    "# http endpoint for your cluster (opensearch required for vector index usage)\n",
    "endpoint = getenv(\"OPENSEARCH_ENDPOINT\", \"http://localhost:9200\")\n",
    "# index to demonstrate the VectorStore impl\n",
    "idx = getenv(\"OPENSEARCH_INDEX\", \"test_pdf_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Configure OpenSearchVectorClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpensearchVectorClient stores text in this field by default\n",
    "text_field = \"content_text\"\n",
    "# OpensearchVectorClient stores embeddings in this field by default\n",
    "embedding_field = \"embedding\"\n",
    "# OpensearchVectorClient encapsulates logic for a\n",
    "# single opensearch index with vector search enabled with hybrid search pipeline\n",
    "client = OpensearchVectorClient(\n",
    "    endpoint=endpoint,\n",
    "    index=idx,\n",
    "    dim=dim,\n",
    "    embedding_field=embedding_field,\n",
    "    text_field=text_field,\n",
    "    search_pipeline=\"hybrid-search-pipeline\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Initialize OpensearchVectorStore\n",
    "We create an instance of OpensearchVectorStore using the configured client. This provides an interface for managing the vector store within the Llama Index framework, facilitating easy integration with other Llama Index functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize vector store\n",
    "vector_store = OpensearchVectorStore(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Create VectorStoreIndex and Store Embeddings\n",
    "In this step, we’ll create a VectorStoreIndex using Llama Index and explicitly store our document embeddings in OpenSearch. This process enables efficient semantic search and retrieval of information from our processed documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Create a StorageContext\n",
    "Here, we create a StorageContext using the vector_store (OpenSearch) we initialized in the previous step. This StorageContext provides a standardized interface for managing storage in Llama Index and connects our index to the OpenSearch vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 Create VectorStoreIndex, Generate and Store Embeddings\n",
    "In this crucial step, we create the VectorStoreIndex, generate embeddings for our documents, and store them in OpenSearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(\n",
    "    token_nodes, storage_context=storage_context, embed_model=embedding_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use the index to answer questions about the PDF content\n",
    "In this section, we’ll use our created index to answer questions about the content of our PDF documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 Set up the retriever\n",
    "We create a retriever from our index with the following parameters:\n",
    "\n",
    "similarity_top_k=3: This specifies that we want to retrieve the top 3 most similar results.\n",
    "\n",
    "vector_store_query_mode=VectorStoreQueryMode.HYBRID: This enables hybrid search, combining both keyword and semantic search for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "retriever = index.as_retriever(similarity_top_k=3,vector_store_query_mode=VectorStoreQueryMode.HYBRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 Define the query\n",
    "This is the question we want to ask about our PDF content.\n",
    "\n",
    "this part we should use our own question. it is the question regarding legal principle from article 291 criminal law."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question is deliberately not mention to article 291 in criminal law. we wan to see whether the model can understand this and retrive the correct document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = \"นายดำเข้าแย่งมีดจากนายแดง และนายดำถูกแทงเสียชีวิต หากข้อเท็จจริงฟังได้ว่านายดำสดุดเท้าตัวเองแล้วล้มมาโดนมีดแทงจุดสำคัญเป็นเหตุให้ถึงแก่ความตาย นายแดงจะอ้างว่าเป็นการป้องกันตัวโดยชอบด้วยกฎหมาย ตาม มาตรา 68 ได้หรือไม่ ศาลจะวินิจฉัยอย่างไร\"\n",
    "question = \"นายดำเข้าแย่งมีดจากนายแดง และนายดำถูกแทงเสียชีวิต หากข้อเท็จจริงฟังได้ว่านายดำสดุดเท้าตัวเองแล้วล้มมาโดนมีดแทงจุดสำคัญเป็นเหตุให้ถึงแก่ความตาย นายแดงจะอ้างว่าเป็นการป้องกันตัวโดยชอบด้วยกฎหมาย ตาม มาตรา 68 ได้หรือไม่ เพราะอะไร\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"นายดำเข้าแย่งมีดจากนายแดง และนายดำถูกแทงเสียชีวิต หากข้อเท็จจริงฟังได้ว่านายดำสดุดเท้าตัวเองแล้วล้มมาโดนมีดแทงจุดสำคัญเป็นเหตุให้ถึงแก่ความตาย นายแดงจะอ้างว่าเป็นการป้องกันตัวโดยชอบด้วยกฎหมาย ตาม มาตรา 68 ได้หรือไม่ เพราะอะไร ให้ยกตัวอย่างคำพิพากษาศาลฎีกาหรือหมายเลขคดีแดงเรื่องนี้ด้วย\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 Retrieve relevant information\n",
    "We use the retriever to find the most relevant information from our indexed documents based on the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = retriever.retrieve(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = retriever.retrieve(question2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.4 Display the results\n",
    "We iterate through the retrieved results, printing both the metadata and the content of each retrieved chunk.\n",
    "\n",
    "This step demonstrates how we can use our indexed documents to retrieve relevant information based on a natural language query. The hybrid search mode allows us to leverage both keyword matching and semantic similarity, potentially providing more accurate and contextually relevant results.\n",
    "\n",
    "By using this approach, we can efficiently answer questions about the content of our PDF documents, even if the exact wording doesn’t match what’s in the documents. This is particularly useful for creating intelligent document querying systems or chatbots that can understand and respond to questions about specific document contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m prompt:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(r\u001b[38;5;241m.\u001b[39mmetadata)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(r)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt' is not defined"
     ]
    }
   ],
   "source": [
    "for r in prompt:\n",
    "    print(r.metadata)\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '1', 'file_name': '1597_2562.pdf', 'file_path': '/Volumes/SS2305_1MH01/data-src/kdai-llm-final-20241007/pdf_corpus/1597_2562.pdf', 'file_type': 'application/pdf', 'file_size': 124005, 'creation_date': '2024-10-08', 'last_modified_date': '2024-10-03'}\n",
      "Node ID: b4d6695e-9edd-4456-96a5-f0423e75d7fe\n",
      "Text: \u0000กา\u0000ด\u0000นเ\u0000ยว\u0000บ\u0000ญหา\u0000อกฎหมาย \u0000\u0000พากษาศาล\u0000กา\u0000\n",
      "1597/2562พ\u0000กงาน\u0000ยการ\u0000งห\u0000ด\u0000มพร โจท\u0000 นาย ส . \u0000เลย ป.อ. มาตรา  68, 288,\n",
      "291 การกระ\u0000\u0000งจะเ\u0000นการ\u0000อง\u0000นโดยชอบ\u0000วยกฎหมายตาม  ป . อ . มาตรา  68 \u0000อง\n",
      "เ\u0000นการกระ\u0000โดยเจตนา  \u0000เลยเอาอา\u0000ธ\u0000นออกมา\u0000\u0000ตายและ\u0000\u0000น\u0000นโดยประมาท\n",
      "\u0000ก\u0000ตาย\u0000งแ\u0000ความตายไ\u0000ใ\u0000การกระ\u0000โดยเจตนา  การกระ\u0000ของ\u0000เลย\u0000งไ\u0000ใ\u0000การ \u0000อง\u0000น\n",
      "___________________________ โจท\u0000\u0000องขอใ\u0000...\n",
      "Score:  1.000\n",
      "\n",
      "{'page_label': '5', 'file_name': '1597_2562.pdf', 'file_path': '/Volumes/SS2305_1MH01/data-src/kdai-llm-final-20241007/pdf_corpus/1597_2562.pdf', 'file_type': 'application/pdf', 'file_size': 124005, 'creation_date': '2024-10-08', 'last_modified_date': '2024-10-03'}\n",
      "Node ID: b1a95e97-af8f-4d57-a2c2-891640e53402\n",
      "Text: 68 \u0000องเ\u0000นการกระ\u0000โดยเจตนา  เ\u0000อ\u0000อเ\u0000จจ\u0000ง\u0000งไ\u0000\u0000า\u0000เลยเอาอา\u0000ธ\u0000นออก\n",
      "มา\u0000ง\u0000\u0000ตายใน\u0000ดแรก  และเ\u0000อกอดป\u0000\u0000น  กระ\u0000น\u0000น\u0000ก\u0000ตาย  2 \u0000ด  เ\u0000นการ\u0000\u0000น\u0000น\n",
      "โดยประมาทเ\u0000นเห\u0000ใ\u0000\u0000ตาย\u0000งแ\u0000ความตายไ\u0000ใ\u0000กระ\u0000โดยเจตนา  การกระ\u0000ของ\n",
      "\u0000เลย\u0000งไ\u0000ใ\u0000เ\u0000นการ\u0000อง\u0000นโดยชอบ\u0000วยกฎหมายตามประมวลกฎหมายอาญา  มาตรา 68\n",
      "\u0000กา\u0000อ\u0000ของ\u0000เลย\u0000งไ\u0000\u0000น \u0000วน\u0000\u0000เลย\u0000กาขอใ\u0000รอทางลงโทษ\u0000น  เ\u0000น\u0000า\n",
      "พฤ\u0000การ\u0000\u0000\u0000เลยพาอา\u0000ธ\u0000นไป \u0000ง\u0000าน\u0000เ\u0000ดเห\u0000โดย...\n",
      "Score:  1.000\n",
      "\n",
      "{'page_label': '5', 'file_name': '1597_2562.pdf', 'file_path': '/Volumes/SS2305_1MH01/data-src/kdai-llm-final-20241007/pdf_corpus/1597_2562.pdf', 'file_type': 'application/pdf', 'file_size': 124005, 'creation_date': '2024-10-07', 'last_modified_date': '2024-10-03'}\n",
      "Node ID: 901377d8-8506-4ce3-aba8-671bfa5bbb73\n",
      "Text: 68 \u0000องเ\u0000นการกระ\u0000โดยเจตนา  เ\u0000อ\u0000อเ\u0000จจ\u0000ง\u0000งไ\u0000\u0000า\u0000เลยเอาอา\u0000ธ\u0000นออก\n",
      "มา\u0000ง\u0000\u0000ตายใน\u0000ดแรก  และเ\u0000อกอดป\u0000\u0000น  กระ\u0000น\u0000น\u0000ก\u0000ตาย  2 \u0000ด  เ\u0000นการ\u0000\u0000น\u0000น\n",
      "โดยประมาทเ\u0000นเห\u0000ใ\u0000\u0000ตาย\u0000งแ\u0000ความตายไ\u0000ใ\u0000กระ\u0000โดยเจตนา  การกระ\u0000ของ\n",
      "\u0000เลย\u0000งไ\u0000ใ\u0000เ\u0000นการ\u0000อง\u0000นโดยชอบ\u0000วยกฎหมายตามประมวลกฎหมายอาญา  มาตรา 68\n",
      "\u0000กา\u0000อ\u0000ของ\u0000เลย\u0000งไ\u0000\u0000น \u0000วน\u0000\u0000เลย\u0000กาขอใ\u0000รอทางลงโทษ\u0000น  เ\u0000น\u0000า\n",
      "พฤ\u0000การ\u0000\u0000\u0000เลยพาอา\u0000ธ\u0000นไป \u0000ง\u0000าน\u0000เ\u0000ดเห\u0000โดย...\n",
      "Score:  0.003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for r in prompt2:\n",
    "    print(r.metadata)\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Implement Few-Shot Learning with OpenThaiGPT on Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1 Set up Ollama with OpenThaiGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: unknown command \"search\" for \"ollama\"\n"
     ]
    }
   ],
   "source": [
    "!ollama search openthaigpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \u001b[?25h\n",
      "Error: pull model manifest: file does not exist\n"
     ]
    }
   ],
   "source": [
    "!ollama pull openthaigpt:latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               ID              SIZE      MODIFIED      \n",
      "llama3.2:latest    a80c4f17acd5    2.0 GB    7 minutes ago    \n"
     ]
    }
   ],
   "source": [
    "! ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2 Create a function to query OpenThaiGPT\n",
    "This function takes the user’s question and the retrieved context, formats them into a prompt, and sends it to the OpenThaiGPT model running on Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#this is example from Aj. we skip this part and use our own prompt regarding article 291 in the next cell.\\nimport ollama\\n\\ndef query_openthaigpt(question, context):\\n    formatted_prompt = f\\'\\'\\'# Few-shot examples\\nExample 1:\\nContext: An ONT (Optical Network Terminal) device is unable to connect to the network.\\nQuestion: What are the steps to troubleshoot an ONT that cannot connect?\\nAnswer: 1. Check the fiber optic cable connection.\\n2. Restart the ONT device.\\n3. Verify the status lights on the device.\\n4. Test the connection with a spare ONT.\\n5. Contact technical support if the issue persists.\\n\\nExample 2:\\nContext: A customer complains about slow internet speed in their FTTX system.\\nQuestion: What is the procedure for diagnosing and fixing slow internet speed in an FTTX system?\\nAnswer: 1. Run an internet speed test using a speed testing tool.\\n2. Check the Wi-Fi router settings.\\n3. Test the connection directly to the ONT using an Ethernet cable.\\n4. Verify the optical signal strength at the ONT.\\n5. Check the customer\\'s bandwidth usage.\\n6. Adjust device settings or replace faulty equipment if necessary.\\n\\n# RAG component\\nRetrieved information:\\n{context}\\n\\n# Actual question\\nQuestion: {question}\\n\\nPlease answer the question with Thai language using the information from the examples and the retrieved information above. Focus on troubleshooting end-user devices in FTTX projects. Provide a clear, step-by-step answer, prioritized in order of importance. Include a brief explanation for each step. If the provided information is insufficient to answer the question completely, state \"The available information is not sufficient to fully answer this question\" and suggest general troubleshooting steps.\\n\\nAnswer:\\'\\'\\'\\n\\n    #print(formatted_prompt)\\n    response = ollama.generate(model=\\'openthaigpt:latest\\', prompt=formatted_prompt)\\n    return response[\\'response\\']\\n\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#this is example from Aj. we skip this part and use our own prompt regarding article 291 in the next cell.\n",
    "import ollama\n",
    "\n",
    "def query_openthaigpt(question, context):\n",
    "    formatted_prompt = f'''# Few-shot examples\n",
    "Example 1:\n",
    "Context: An ONT (Optical Network Terminal) device is unable to connect to the network.\n",
    "Question: What are the steps to troubleshoot an ONT that cannot connect?\n",
    "Answer: 1. Check the fiber optic cable connection.\n",
    "2. Restart the ONT device.\n",
    "3. Verify the status lights on the device.\n",
    "4. Test the connection with a spare ONT.\n",
    "5. Contact technical support if the issue persists.\n",
    "\n",
    "Example 2:\n",
    "Context: A customer complains about slow internet speed in their FTTX system.\n",
    "Question: What is the procedure for diagnosing and fixing slow internet speed in an FTTX system?\n",
    "Answer: 1. Run an internet speed test using a speed testing tool.\n",
    "2. Check the Wi-Fi router settings.\n",
    "3. Test the connection directly to the ONT using an Ethernet cable.\n",
    "4. Verify the optical signal strength at the ONT.\n",
    "5. Check the customer's bandwidth usage.\n",
    "6. Adjust device settings or replace faulty equipment if necessary.\n",
    "\n",
    "# RAG component\n",
    "Retrieved information:\n",
    "{context}\n",
    "\n",
    "# Actual question\n",
    "Question: {question}\n",
    "\n",
    "Please answer the question with Thai language using the information from the examples and the retrieved information above. Focus on troubleshooting end-user devices in FTTX projects. Provide a clear, step-by-step answer, prioritized in order of importance. Include a brief explanation for each step. If the provided information is insufficient to answer the question completely, state \"The available information is not sufficient to fully answer this question\" and suggest general troubleshooting steps.\n",
    "\n",
    "Answer:'''\n",
    "\n",
    "    #print(formatted_prompt)\n",
    "    response = ollama.generate(model='openthaigpt:latest', prompt=formatted_prompt)\n",
    "    return response['response']\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ถาม: นาย A ฆ่าคนตายโดยอ้างว่าเป็นการป้องกันตัวโดยชอบด้วยกฎหมาย ตาม ป.อาญา ม.68 หากข้อเท็จจริงฟังได้ว่ามีการยื้อแย่งอาวุธปืนและอาวุธปืนลั่น ศาลจะวินิจฉัยอย่างไร\n",
    "\n",
    "ตอบ: ศาลจะตดสินว่าคำให้การของจำเลยฟังไม่ขึ้น ด้วยว่าการป้องกันตัวโดยชอบด้วยกฎหมาย ตาม ม.68 จะต้องเป็นการกระทำโดยเจตนา เมื่อข้อเท็จจริงฟังได้ว่ามีการยื้อแย่งปืน และปืนลั่น จึงเป็นการกระทำโดยประมาท เป็นเหตุให้ถึงแก่ความตาย ไม่ใช่การกระทำโดยเจตนา ไม่เป็นการป้องกันตัวโดยชอบด้วยกฎหมาย\n",
    "\n",
    "#english text translated by Claude AI 3.5 sonnet.\n",
    "Question: Mr. A killed a person and claimed it was justifiable self-defense under Section 68 of the Criminal Code. If the facts indicate that there was a struggle for a firearm and the gun accidentally discharged, how would the court rule?\n",
    "Answer: The court would likely determine that the defendant's claim of self-defense is not tenable. Justifiable self-defense under Section 68 requires intentional action. Given that the facts indicate a struggle for the firearm and an accidental discharge, this constitutes a negligent act resulting in death, not an intentional act. Therefore, it does not meet the criteria for justifiable self-defense under the law.\n",
    "The court would likely rule that this case falls under negligent homicide rather than justifiable self-defense, as the element of intent, which is crucial for the self-defense claim, is absent in the scenario where the firearm discharged accidentally during a struggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def query_openthaigpt(question, context):\n",
    "    formatted_prompt = f'''# Few-shot examples\n",
    "Example 1:\n",
    "Context: Mr. A killed a person and claimed it was justifiable self-defense under Section 68 of the Criminal Code.\n",
    "If the facts indicate that there was a struggle for a firearm and the gun accidentally discharged.\n",
    "Question: How would the court rule? Please provide an example Supreme Court decision case number or the Red case number (หมายเลขคดีแดง)\n",
    "Answer: The court would likely determine that the defendant's claim of self-defense is not tenable. Justifiable self-defense under Section 68 requires intentional action. Given that the facts indicate a struggle for the firearm and an accidental discharge, this constitutes a negligent act resulting in death, not an intentional act. Therefore, it does not meet the criteria for justifiable self-defense under the law.\n",
    "The court would likely rule that this case falls under negligent homicide rather than justifiable self-defense,\n",
    "as the element of intent, which is crucial for the self-defense claim,\n",
    "is absent in the scenario where the firearm discharged accidentally during a struggle.\n",
    "The example Supreme Court decision is Case No. 1597/2562, Red Case No. อ632/2560.\n",
    "\n",
    "# RAG component\n",
    "Retrieved information:\n",
    "{context}\n",
    "\n",
    "# Actual question\n",
    "Question: {question}\n",
    "\n",
    "Please answer the question with Thai language using the information from the examples and the retrieved information above. Focus on troubleshooting end-user devices in FTTX projects. Provide a clear, step-by-step answer, prioritized in order of importance. Include a brief explanation for each step. If the provided information is insufficient to answer the question completely, state \"The available information is not sufficient to fully answer this question\" and suggest general troubleshooting steps.\n",
    "\n",
    "Answer:'''\n",
    "\n",
    "    #print(formatted_prompt)\n",
    "    #response = ollama.generate(model='openthaigpt:latest', prompt=formatted_prompt)\n",
    "    response = ollama.generate(model='llama3.2:latest', prompt=formatted_prompt)\n",
    "    return response['response']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.3 Integrate OpenThaiGPT with our retriever\n",
    "Now, let’s modify our question-answering process to use OpenThaiGPT:\n",
    "\n",
    "This function retrieves relevant information using our previously set up retriever, combines the retrieved text into a context, and then uses OpenThaiGPT to generate an answer based on this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: นายดำเข้าแย่งมีดจากนายแดง และนายดำถูกแทงเสียชีวิต หากข้อเท็จจริงฟังได้ว่านายดำสดุดเท้าตัวเองแล้วล้มมาโดนมีดแทงจุดสำคัญเป็นเหตุให้ถึงแก่ความตาย นายแดงจะอ้างว่าเป็นการป้องกันตัวโดยชอบด้วยกฎหมาย ตาม มาตรา 68 ได้หรือไม่ เพราะอะไร\n",
      "Answer: 1. นายแดงจะไม่สามารถอ้างว่าเป็นการป้องกันตัวโดยชอบด้วยกฎหมาย ตาม มาตรา 68 ได้ เนื่องจากการกระทำของนายแดงเป็นการตอบสนองต่อการถูกโจมตี ซึ่งไม่ค่อยได้รับการยอมรับในข้อเท็จจริงฟังได้ว่านายแดงสดุดเท้าตัวเองแล้วล้มมาโดนมีดแทงจุดสำคัญ\n",
      "2. การใช้มาตรา 68 ต้องอาศัยการกระทำที่เกิดขึ้นโดยเจตนา ซึ่งนอกจากการป้องกันตัวในกรณีนี้ ยังมีการโจมตีของนายแดงด้วยมีด \n",
      "3. ในการขยายความตาม มาตรา 288 และ 291 โดยอาจพิจารณาคดีเป็นการเสียชีวิตอย่างไม่สมเหตุสมผลหรือโดยประมาท เนื่องจากสามารถสันนิษฐานได้ว่ามีนัยยะของการโจมตีที่รุนแรงมากขึ้นซึ่งล้ำเกณฑ์ความจำเป็นในการป้องกันตัว\n",
      "4. ดังนั้น การอ้างว่าเป็นการป้องกันตัวตาม มาตรา 68 จะต้องมีการพิสูจน์ที่แน่นอนและสมเหตุสมผลมากกว่านี้\n"
     ]
    }
   ],
   "source": [
    "def answer_question(question):   \n",
    "    # Query OpenThaiGPT\n",
    "    answer = query_openthaigpt(question, prompt[0])\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "answer = answer_question(question)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: นายดำเข้าแย่งมีดจากนายแดง และนายดำถูกแทงเสียชีวิต หากข้อเท็จจริงฟังได้ว่านายดำสดุดเท้าตัวเองแล้วล้มมาโดนมีดแทงจุดสำคัญเป็นเหตุให้ถึงแก่ความตาย นายแดงจะอ้างว่าเป็นการป้องกันตัวโดยชอบด้วยกฎหมาย ตาม มาตรา 68 ได้หรือไม่ เพราะอะไร ให้ยกตัวอย่างคำพิพากษาศาลฎีกาหรือหมายเลขคดีแดงเรื่องนี้ด้วย\n",
      "Answer: การอ้างว่าเป็นการป้องกันตัวโดยชอบด้วยกฎหมาย ตาม มาตรา 68 กฎหมายแพทย์ไม่สามารถใช้ได้ในกรณีนี้ เนื่องจากข้อเท็จจริงที่ว่านายดำสดุดเท้าตัวเองแล้วล้มมาโดนมีดแทงจุดสำคัญเป็นเหตุให้ถึงแก่ความตาย ซึ่งไม่ใช่การกระทำโดยเจตนา แต่เป็นการกระทำโดยประมาท\n",
      "\n",
      "การป้องกันตัวโดยชอบด้วยกฎหมาย ตาม มาตรา 68 ต้องมีองค์ประกอบของการกระทำโดยเจตนาของผู้กระทำ และไม่มีการกระทำโดยเจตนาของตนเองในการป้องกันตัวในกรณีนี้ ไม่มีการกระทำที่เป็นการป้องกันตัวอย่างจริงจัง\n",
      "\n",
      "ดังนั้น นายแดงไม่สามารถอ้างว่าเป็นการป้องกันตัวโดยชอบด้วยกฎหมาย ตาม มาตรา 68 ได้ หากข้อเท็จจริงฟังได้ว่านายดำสดุดเท้าตัวเองแล้วล้มมาโดนมีดแทงจุดสำคัญเป็นเหตุให้ถึงแก่ความตาย\n",
      "\n",
      "หมายเลขคดีแดงเรื่องนี้ไม่ได้กล่าวไว้ในข้อมูลที่ให้มา\n"
     ]
    }
   ],
   "source": [
    "def answer_question(question2):   \n",
    "    # Query OpenThaiGPT\n",
    "    answer = query_openthaigpt(question2, prompt2[0])\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "answer = answer_question(question2)\n",
    "print(f\"Question: {question2}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
